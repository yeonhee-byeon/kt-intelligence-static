<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- SEO -->
    <title>KT Voice AI를 소개합니다.</title>
    <meta name="description" content="듣고, 말하고, 이해하는 Voice AI 전 영역을 자체 기술로 제공">
    <meta name="keywords" content="음성기술, 음성인식, 음성합성, 화자인식">

    <!-- SNS 공유용 -->
    <meta property="og:title" content="KT Voice AI를 소개합니다.">
    <meta property="og:description" content="듣고, 말하고, 이해하는 Voice AI 전 영역을 자체 기술로 제공">
    <meta property="og:type" content="website">
    <meta property="og:site_name" content="KT AI">

    <!-- Common CSS -->
    <link rel="stylesheet" href="/css/ai/common/common.css" />
    <!-- Reset CSS -->
    <link rel="stylesheet" href="/css/ai/common/reset.css" />
    <!-- Style CSS -->
    <link rel="stylesheet" href="/css/ai/solution_cy.css" />
    <!-- AOS CSS -->
    <link rel="stylesheet" href="/css/ai/common/aos.css" />
</head>

<body>
    <!-- Header -->
    <header id="main-header" class="header">
        <div class="header-inner"></div>
    </header>

    <div class="sub-content techDetailPage">
        <div class="sub-inner">
            <div class="tech-detail-header">
                <span class="tech-detail-category">What's New</span>
                <h1 class="tech-detail-title">
                    KT Voice AI를 소개합니다.
                </h1>
                <div class="card-tags">
                    <span>음성기술</span>
                    <span>음성인식</span>
                    <span>음성합성</span>
                    <span>화자인식</span>
                </div>
                <time class="tech-detail-date" datetime="2025-05-16">2025.05.16</time>
            </div>

            <!-- 게시글 본문 영역 (관리자 에디터/HTML 입력용) -->
            <article class="tech-detail-article" id="tech-detail-article">
                <!--
                      ※ 관리자 페이지에서 등록한 게시글의 본문(HTML)이 이 영역에 삽입됩니다.
                      예시:
                      <h2>본문 제목</h2>
                      <p>본문 내용...</p>
                      <img src="..." alt="..." />
                      ...
                    -->

                <!-- 작업요청 -->
                <section class="post-custom">
                    <p>
                        KT의 Voice AI 기술은 고객과의 모든 접점을 음성으로 시작해서 음성으로
                        종료할 수 있게 바꾸고 있습니다.
                    </p>
                    <p>
                        KT는 100번 고객센터를 시작으로, 지니TV, 기가지니, AICC(AI고객센터), AI
                        통화비서, 지능망 서비스, 로봇 등 다양한 서비스에 음성 기술을 폭넓게
                        적용해 왔습니다. 이러한 기술은 단순한 음성 명령을 넘어서, 고객의 의도와
                        감정을 이해하고 상황에 맞는 응답을 생성하는 등 보다 정교한 대화형 AI로
                        진화하고 있습니다.
                    </p>
                    <p>
                        KT는 음성인식(ASR), 음성합성(TTS), 화자인식(Speaker Recognition) 등
                        Voice AI 전 영역을 자체 기술로 확보하고 고도화하고 있습니다.
                    </p>
                </section>

                <section class="post-custom">
                    <h3>KT Voice AI 기술의 특징 및 활용</h3>
                    <h4>1. 음성인식 (Speech-to-Text)</h4>
                    <p>
                        KT의 음성인식 기술은 기존의 음향모델(Acoustic Model)과 언어모델(Language
                        Model)을 분리하여 사용하는 하이브리드 방식에서, 두 모델을 통합한 Transformer 기반 End-to-End 구조로 진화했습니다. 이를 통해 Hybrid 방식의
                        복잡성을 극복하고, 다양한 도메인에서도 기존보다
                        정확한 음성 인식을 가능하게 하였습니다. End-to-End 방식 적용을 통해 전체 음성 인식 과정을 통합적으로 학습하여 효율성을 높였고, 자유 발화, 다양한 주제,
                        불규칙한 문장 구조 등 현실 대화 환경에서도 더욱 안정적이고 정확한 인식 성능을 제공합니다.
                        이는 사용자와 AI가 다양한 주제로 깊이 있는 대화를 나누는 'Agent 시대'에 핵심적인 요소입니다.
                    </p>
                    <p>
                        뿐만 아니라, 딥러닝 기반의 고도화된 아키텍처를 유지하면서도 지속적인 경량화 및 최적화 연구를 통해, GPU와 같은 고비용의 특수 하드웨어 없이 CPU 환경에서도 뛰어난
                        성능을 발휘하도록 구현하였습니다.
                        이는 다양한 서비스 환경에 보다 유연하고 경제적으로 음성 인식 기술을 적용할 수 있는 강력한 기반이 됩니다.
                    </p>
                    <p>현재 음성인식 기술은 지니 TV 등 B2C 사업 뿐만 아니라, 고객센터 상담 자동화와 지능형 응답 서비스가 필요한 AICC 등 B2B 시장에 널리 적용되고 있습니다.</p>
                </section>

                <section class="post-custom">
                    <h4>2. 음성합성 (Text-to-Speech)</h4>
                    <p>
                        KT의 음성합성 기술은 기존의 텍스트 분석 음향 예측 보코더 단계를 별도로 처리하던 Cascade 방식에서 벗어나, 자연스러운 억양과 감정 표현이 가능한
                        Transformer 기반 End-to-End TTS 아키텍처를 적용하여, 사람처럼 자연스럽고 고품질의 음성을 생성할 수 있는 것이 큰 특징입니다. 또한 단순한 문장 낭독을
                        넘어 다양한 보이스, 스타일을 제공하고, 한국어의 다양한 표현을 정확히 구현하기 위해 숫자·기호·약어 등을 자동 변환하는 Text Normalization 기술도 정교하게
                        설계되었습니다. Text Normalization, 숫자 및 기호처리 등 세분화된 전처리 기술이 적용되어, 고품질 음성과 언어 표현의 자연성을 동시에 구현하고 있습니다.
                    </p>
                    <p>
                        현재 지니 TV를 통해 약 400만 명의 사용자에게 자연스러운 음성 안내를 제공하고 있으며, 100번 고객센터의 AI 보이스봇, AI 통화 비서, 지능망 서비스 등에도
                        적용되어 실제 서비스 현장에서 고품질 음성합성의 효과를 입증하고 있습니다. 특히 2024년에는 금융권 대상 AICC에 음성합성 서비스를 공급하면서, B2B 사업도 본격적으로
                        추진 중입니다.
                    </p>
                    <p>KT는 앞으로 음성합성 기술을 미디어, 콘텐츠 제작 등 창작 기반 산업으로 확장할 계획입니다. 2025년에는 사용자가 자연어로 스타일을 제어할 수 있는 감정 기반 음성합성
                        기능을 출시할 예정이며, 광고, 더빙, 인터랙티브 콘텐츠 등에서 몰입도 높은 사용자 경험을 제공할 수 있도록 기술 고도화를 지속하고 있습니다.</p>
                </section>

                <section class="post-custom">
                    <h3 class="fz-sm">
                        3. 화자인식 (Speaker Recognition)
                    </h3>
                    <p>
                        KT의 화자인식 기술은 초기의 Mel-Spectrogram 기반 전통 방식에서 벗어나, 딥러닝 기반 음성 임베딩(Speech Representation) 추출방식으로
                        전환되었습니다. 이를 통해 단일 환경이나 화자에 과도하게 최적화되지 않고, 도메인 전반에 걸쳐 높은 일반화 성능을 확보하여 다양한 서비스에서 안정적으로 화자를 식별할 수
                        있게 되었습니다.
                    </p>
                    <p>
                        KT의 화자인식기술은 현재 고객 인증 및 개인화 서비스에 활용되고 있으며, 보이스피싱 탐지와 같은 보안 분야로도 점차 확장되고 있습니다.
                    </p>
                    <p>
                        2024년 국민건강보험공단 B2B 사업을 수주하여, 공공기관 최초로 목소리 기반 본인 인증 시스템을 성공적으로 구축하였습니다. 특히 고령층 사용자의 다양한 음성 환경을
                        고려한 딥러닝 기반 화자 임베딩 기술을 적용해 높은 일반화 성능과 사용자 편의성을 확보하였습니다. 최근에는 AI 기술로 생성된 딥보이스(Deepfake Voice)를
                        탐지하는 기능까지 통합하여, 인증을 가장한 위변조 음성에 대한 보안 대응력도 강화하였습니다. 이러한 기술적 진화를 바탕으로 KT는 공공·금융 분야뿐 아니라, 향후 다양한
                        산업군에서 신뢰도 높은 음성 기반 인증 플랫폼으로 그 영역을 넓혀가고 있습니다.
                    </p>
                    <p>
                        2025년에는 KT의 화자인식 기술이 고객 안심 서비스를 위한 보이스피싱 대응 영역으로 확장됩니다. 통화 중 등장하는 보이스피싱 범인의 음성을 탐지하는 '그놈목소리ʼ 인식
                        기술, 그리고 가족이나 지인을 사칭하는 딥보이스 공격을 식별하는 탐지 기능이 새롭게 적용될 예정입니다. 이를 통해 KT는 단순한 본인 인증을 넘어, 실시간 음성 보안 및
                        사기 예방 기능까지 아우르는 차세대 음성 인식 플랫폼으로 진화하고 있습니다.
                    </p>
                </section>


                <section class="post-custom">
                    <h3>글로벌대비월등히뛰어난한국어성능과최적화구현</h3>
                    <h4>1. 음성인식 성능</h4>
                    <p>KT의 음성인식 기술은 다양한 현실 환경을 반영한 테스트셋에서 Whisper(OpenAI), OpenAI API, Microsoft Azure API 등 주요 글로벌 음성인식
                        기술 대비 우수한 성능을 입증하였습니다. 특히, 회의, 상담, 저음질 전화망, 한국어 강의 등 다양한 실사용 도메인뿐 아니라 KsponSpeech (eval clean /
                        eval other)에서도 가장 높은 인식 정확도를 기록하고 있습니다.</p>
                    <p>이러한 성능은 KT의 독자적인 Transformer 기반 End-to-End 구조, 도메인 최적화 기술, 그리고 한국어 화자의 실제 발화 특성을 반영한 데이터 설계 덕분에
                        가능했습니다. 또한, GPU 환경뿐만 아니라 CPU 기반 환경에서도 실시간 처리가 가능하도록 최적화되어 있어, 클라우드뿐 아니라 엣지 디바이스나 내장형 시스템에서도 안정적인
                        인식 성능을 제공합니다. 이를 통해 실제 B2B 고객상담, 음성 비서, 회의록 자동화 등 다양한 서비스에서 상용 수준의 품질과 유연한 배포 환경을 모두 만족시키고 있습니다.
                    </p>

                    <div class="table-wrapper">
                        <table>
                            <thead>
                                <th>모델</th>
                                <th>평균</th>
                                <th>저음질 전화망</th>
                                <th>상담</th>
                                <th>한국어 강의</th>
                                <th>회의</th>
                                <th>KspoSpeech eval_clean</th>
                                <th>KspoSpeech eval_other</th>
                            </thead>
                            <tr>
                                <td>gpt-4o-transcribe</td>
                                <td>71.7</td>
                                <td>66.58</td>
                                <td>85.21</td>
                                <td>79.53</td>
                                <td>69.39</td>
                                <td>65.77</td>
                                <td>63.74</td>
                            </tr>
                            <tr>
                                <td>gpt-4o-mini-transcribe</td>
                                <td>67.35</td>
                                <td>58.3</td>
                                <td>78.64</td>
                                <td>76.78</td>
                                <td>69.12</td>
                                <td>61.88</td>
                                <td>59.43</td>
                            </tr>
                            <tr>
                                <td>MS Azure Speech API</td>
                                <td>86.35</td>
                                <td>87.7</td>
                                <td>89.66</td>
                                <td>88.19</td>
                                <td>88.07</td>
                                <td>83.67</td>
                                <td>80.83</td>
                            </tr>
                            <tr>
                                <td>whisper-1</td>
                                <td>88.87</td>
                                <td>83.13</td>
                                <td>92.09</td>
                                <td>89.26</td>
                                <td>89.62</td>
                                <td>89.39</td>
                                <td>89.74</td>
                            </tr>
                            <tr>
                                <td>whisper-large-v3</td>
                                <td>90.71</td>
                                <td>93.18</td>
                                <td>95.26</td>
                                <td>86.94</td>
                                <td>91.29</td>
                                <td>88.84</td>
                                <td>88.72</td>
                            </tr>
                            <tr>
                                <td>KT-E2E</td>
                                <td>94.89</td>
                                <td>95.94</td>
                                <td>97.31</td>
                                <td>93.44</td>
                                <td>93.78</td>
                                <td>94.47</td>
                                <td>94.41</td>
                            </tr>
                        </table>
                        <h5>[참고] 공개 데이터셋인 AI-Hub 데이터셋 정보 :
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/AIHUB_CONFERENCE_MAJOR_AREA_test.txt"
                                target="_blank">주요 영역별 회의</a>
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/AIHUB_CONFERENCE_MAJOR_AREA_test.txt"
                                target="_blank">회의</a>
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/AIHUB_COUNSELING_test.txt"
                                target="_blank">상담</a>
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/AIHUB_TELEPHONE_LOW_QUALITY_test.txt"
                                target="_blank">저음질전화망</a>
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/AIHUB_KOREAN_LECTURE_test.txt"
                                target="_blank">한국어강의</a>
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/README.md"
                                target="_blank">KsponSpeech eval clean</a>
                            <a href="https://github.com/rtzr/Awesome-Korean-Speech-Recognition/blob/main/docs/README.md"
                                target="_blank">KsponSpeech ecal other</a>
                        </h5>
                    </div>
                </section>



                <section class="post-custom">
                    <h4>2. 화자인증 성능</h4>
                    <p>KT의 화자인식 기술은 글로벌 상용 솔루션인 N사와 동일한 조건의 데이터셋으로 평가한 결과, EER(Equal Error Rate) 기준에서 더욱 우수한 성능을 보였으며,
                        FAR(False Acceptance Rate)을 0.1%로 고정한 조건에서의 FRR(False Rejection Rate)에서도 뚜렷한 성능 차이를 나타냈습니다. 이는
                        실제 인증 서비스 환경에서 높은 정확도와 신뢰성을 제공함을 의미합니다.</p>

                    <div class="table-wrapper">
                        <div class="table-info">
                            <h5>EER(Equal Error Rate, 동일오류율) : 사칭률과 본인거부율이 동일할 때의 오류율</h5>
                        </div>
                        <table>
                            <thead>
                                <th>인증 음성 길이</th>
                                <th>KT</th>
                                <th>N사</th>
                            </thead>
                            <tr>
                                <td>5초</td>
                                <td>9.50%</td>
                                <td>30.00%</td>
                            </tr>
                            <tr>
                                <td>10초</td>
                                <td>3.52%</td>
                                <td>12.56%</td>
                            </tr>
                            <tr>
                                <td>15초</td>
                                <td>3.06%</td>
                                <td>8.16%</td>
                            </tr>
                        </table>
                    </div>
                    <div class="table-wrapper">
                        <div class="table-info">
                            <h5>FAR이 0.1%일 때 FRR 성능 비교 (%)</h5>
                            <ul class="innerList">
                                <li>사칭률 (FAR, False Accept Rate) : 타인인증성공 / 사칭시도 총횟수</li>
                                <li>본인거부율 (FRR, False Reject Rate) : 본인인증실패 / 본인시도 총횟수</li>
                            </ul>
                        </div>

                        <table>
                            <thead>
                                <th>인증 음성 길이</th>
                                <th>KT</th>
                                <th>N사</th>
                            </thead>
                            <tr>
                                <td>5초</td>
                                <td>3.24%</td>
                                <td>3.50%</td>
                            </tr>
                            <tr>
                                <td>10초</td>
                                <td>1.50%</td>
                                <td>2.13%</td>
                            </tr>
                            <tr>
                                <td>15초</td>
                                <td>1.53%</td>
                                <td>2.04%</td>
                            </tr>
                        </table>
                    </div>
                </section>

                <section class="post-custom">
                    <p>KT의 Voice AI는 사람과 기술을 연결하는 새로운 기준을 제시합니다. 단순한 기술 적용을 넘어, KT는 음성 기반의 인터페이스를 통해 고객과의 소통을 혁신하고 있으며,
                        지능형 음성 에이전트를 통해 미래형 비즈니스 환경을 구현해 나가고 있습니다. 앞으로도 KT는 On-device AI, 다국어 음성처리, 감정 인식, 연기체 합성 등 차세대
                        기술을 지속적으로 선도하며, 국내외 Voice AI 생태계를 이끄는 중심 기업으로 도약할 것입니다.</p>
                </section>

                <!-- //작업요청 -->

                <!-- <img class="pc-only" src="/resource/images/ai/resources/techDetail_test.png" alt="" />
                <img class="mobile-show" src="/resource/images/ai/resources/techDetail_test_mobile.png" alt="" /> -->
                <div class="tech-detail-article-list">
                    <h3>Publications</h3>
                    <ul>
                        <li><a href="https://arxiv.org/abs/2501.17612" target="_blank">“VoicePrompter: Robust Zero-Shot
                                Voice Conversion with Voice
                                Prompt and Conditional Flow
                                Matching”</a>, ICASSP (2025) Ha-Yeong Choi, Jaehan Park</li>
                        <li><a href="https://icml.cc/virtual/2025/poster/46647" target="_blank">“Do Not Mimic My Voice:
                                Speaker Identity Unlearning for Zero-Shot
                                Text-to-Speech”</a>,
                            ICML
                            (2025) Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee</li>
                        <li><a href="https://arxiv.org/abs/2408.07547" target="_blank">“PeriodWave: Multi-Period Flow
                                Matching for High-Fidelity
                                Waveform Generation”</a>, ICLR
                            (2025)
                            Sang-Hoon Lee, Ha-Yeong Choi, Seong-Whan Lee</li>
                    </ul>
                </div>
            </article>

            <div class="tech-detail-bottom">
                <a href="/ai/resources/">
                    <button type="button" class="basic-bk-btn docs-back">
                        돌아가기
                    </button>
                </a>
                <div class="tech-banner-sec"></div>
            </div>
        </div>
    </div>

    <!-- Footer -->
    <footer class="footer"></footer>

    <!-- Script -->
    <script src="/js/ai/solution.js"></script>
    <script src="/js/ai/common/common.js"></script>
    <script>
        includeCommonLayout({ skipKtModel: true });
    </script>
</body>

</html>